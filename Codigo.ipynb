{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../../standard_import.txt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from sklearn import neighbors, metrics, model_selection\n",
    "import sklearn.tree as tree\n",
    "\n",
    "pd.set_option('display.notebook_repr_html', False)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 150)\n",
    "pd.set_option('display.max_seq_items', None)\n",
    " \n",
    "#%config InlineBackend.figure_formats = {'pdf',}\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numericas:\n",
    "- 'Administrative': Numero de paginas de tipo administrativo\n",
    "- 'Administrative_Duration': mins, duracion en este tipo de paginas\n",
    "- 'Informational': Numeor de paginas de tipo infomracion\n",
    "- 'Informational_Duration': mins, duracion en este tipo de paginas\n",
    "- 'ProductRelated': Numeor de paginas de productos relacionados vistos\n",
    "- 'ProductRelated_Duration': mins, timepo que ha estado en las paginas de productos relacionados\n",
    "- 'BounceRates': Porcentege de visitante que entran y salen sin interacutar\n",
    "- 'ExitRates': Porcentaje de persona que slieron despues de interacutar\n",
    "- 'PageValues': Media de la valoracion de la pagina antes de hacer una transaccion comercial\n",
    "- 'SpecialDay': (0,1) Si el dia esta cerca a un dia especial\n",
    "- 'OperatingSystems':\n",
    "- 'Browser':\n",
    "- 'Region':\n",
    "- 'TrafficType':\n",
    "\n",
    "Categoricas:\n",
    "- 'Month': 'Feb': 2,'Mar': 3,'May': 5,'June': 6,'Jul': 7,'Aug': 8,'Sep': 9,'Oct': 10,'Nov': 11,'Dec': 12\n",
    "- 'Weekend': 1(Fasle), 2(True)\n",
    "- 'VisitorType': 1(Ha vuelto), 2(Nuevo), 3(otro)\n",
    "\n",
    "Clases 'Revenue'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = pd.read_csv('online_shoppers_intention.csv')\n",
    "\n",
    "datos_ok = datos.copy()\n",
    "categorico = ['Month','Weekend','VisitorType','Revenue']\n",
    "\n",
    "for i,val in enumerate(datos_ok.columns):\n",
    "    if val == 'Month':\n",
    "        mesesDic = dict(zip(['Feb', 'Mar', 'May', 'June', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'], [2,3,5,6,7,8,9,10,11,12]))\n",
    "        datos_ok[val].replace(mesesDic, inplace=True)\n",
    "    elif val in categorico:\n",
    "        labels = datos_ok[val].astype('category').cat.categories.tolist()\n",
    "        dict_make = {val : {k: v for k,v in zip(labels,list(range(1,len(labels)+1)))}}\n",
    "        datos_ok[val].replace(dict_make[val], inplace=True)\n",
    "\n",
    "X_all = np.array(datos_ok.drop(columns = 'Revenue').copy())\n",
    "y_all = np.array(pd.factorize(datos_ok['Revenue'])[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elimnacion de valores Perididos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = np.isnan(X_all)\n",
    "n = np.sum(n,axis=1).reshape(-1,1).astype('bool')\n",
    "n = n == False\n",
    "X = X_all[n.flatten()]\n",
    "y = y_all[n.flatten()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Hot Ecnode busqueda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(12330, 17)\nEl rendimiento en entrenamiento con todas las variables es el 100.0%\nEl rendimiento en test con todas las variables es el 85.9%\n"
    }
   ],
   "source": [
    "#hanwei\n",
    "print(X_all.shape)\n",
    "n = np.isnan(X_all)\n",
    "\n",
    "# Se fija la semilla de numpy para que la generación aleatoria siempre nos de los mismos números\n",
    "np.random.seed(12)\n",
    "\n",
    "# Lllamada a la función train_test_split y guardado del resultado\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, train_size=0.7)\n",
    "\n",
    "# Realizamos el proceso para KNN por lo que hay que llamar al constructor de dicho clasificador\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "\n",
    "# Llamada a la función que realiza el aprendizaje del clasificador\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "# Llamada a la función que realiza la predicción de los datos de entrenamiento\n",
    "predTrain = clf.predict(X_train)\n",
    "\n",
    "# Llamada a la función que calcula el porcentaje de acierto para los datos de entrenamiento\n",
    "accTrain = round(metrics.accuracy_score(y_train,predTrain)*100,2)\n",
    "print('El rendimiento en entrenamiento con todas las variables es el {}%'.format(accTrain))\n",
    "\n",
    "# Llamada a la función que realiza la predicción de los datos de test\n",
    "predTest = clf.predict(X_test)\n",
    "\n",
    "# Llamada a la función que calcula el porcentaje de acierto para los datos de test\n",
    "accTest = round(metrics.accuracy_score(y_test,predTest)*100,2)\n",
    "print('El rendimiento en test con todas las variables es el {}%'.format(accTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1908 10422\n[0 0 0 ... 0 0 0]\n"
    }
   ],
   "source": [
    "num = np.sum(datos['Revenue'] == 1)\n",
    "num2 = np.sum(datos['Revenue'] == 0)\n",
    "print(num,num2)\n",
    "print(y_all)\n",
    "\n",
    "x_pos = X_all[y_all == 1]\n",
    "x_pos = X_all[y_all == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Las variables seleccionadas son  ['Administrative_Duration', 'ProductRelated', 'ProductRelated_Duration', 'BounceRates', 'ExitRates', 'PageValues']\n99.9652012527549\n84.92557510148849\n"
    }
   ],
   "source": [
    "XsinOutliers = X.copy()\n",
    "YsinOutliers = y.copy()\n",
    "# Se importa la función que permite seleccionar variables a partir de un modelo\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "np.random.seed(12)\n",
    "semilla = 123\n",
    "\n",
    "# Se llama al constructor del árbol de decisión\n",
    "arbolDecision = tree.DecisionTreeClassifier()\n",
    "\n",
    "# Se aplica la selección a partir del modelo\n",
    "model = SelectFromModel(estimator=arbolDecision)\n",
    "\n",
    "# Se entrena el objeto de la clase SelectFromModel\n",
    "model.fit(XsinOutliers, YsinOutliers)\n",
    "\n",
    "# Se transforman los datos originales de entrenamiento de acuerdo a las variables seleccionadas\n",
    "X_new = model.transform(XsinOutliers)\n",
    "\n",
    "# Se obtienen las variables seleccionadas: lista de booleanos\n",
    "booleanas =  model.get_support()\n",
    "\n",
    "# Se obtienen los nombres de las variables seleccionadas\n",
    "variablesSeleccionadas = [datos_ok.columns[:-1][i] for i in range(len(datos_ok.columns)-1) if booleanas[i]==True]\n",
    "print(\"Las variables seleccionadas son \", variablesSeleccionadas)\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X_new, YsinOutliers, train_size=0.7)\n",
    "# Llamada al constructor del árbol de decisión\n",
    "arbolDecision = tree.DecisionTreeClassifier()\n",
    "\n",
    "# Entrenamiento del árbol de decisión con los datos transformados\n",
    "arbolDecision.fit(X_train,y_train)\n",
    "\n",
    "# Predicción de las clases de los datos de entrenamiento transformados\n",
    "prediccionesTrain = arbolDecision.predict(X_train)\n",
    "prediccionesTest = arbolDecision.predict(X_test)\n",
    "\n",
    "# Se obtiene el accuracy en enrenamiento del nuevo árbol\n",
    "accuracyTrain =  metrics.accuracy_score(y_train,prediccionesTrain)*100\n",
    "print(accuracyTrain)\n",
    "\n",
    "# Obtenición del rendimiento con los datos de test\n",
    "accuracyTest =  metrics.accuracy_score(y_test,prediccionesTest)*100\n",
    "print(accuracyTest)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "def leaveOneOut(clasificador, X, y):\n",
    "    \"\"\"\n",
    "    :param clasificador: Instancia de un clasificador de Scikit-Learn entrenada (con fit hecho con los datos de train o el subconjunto seleccionado)\n",
    "    :param X: Matriz con los ejemplos de entrenamiento completo (para hacer leave one out)\n",
    "    :param y: Vector con la salida de los ejemplos de entrenamiento completo (correspondientes a X)\n",
    "    :return: Vector con la salida obtenida para cada ejemplo de X (siguiendo el esquema leave-one-out)\n",
    "    \"\"\"\n",
    "    # En caso de que el clasificador no sea KNN simplemente se utiliza el clasificador aprendido y se predicen los ejemplos con dicho clasificador\n",
    "    if type(clasificador) != neighbors.KNeighborsClassifier:\n",
    "        # Utiliza el método predict para obtener la predicción\n",
    "        prediction = clasificador.predict(X)\n",
    "        return prediction\n",
    "    \n",
    "    # En otro caso será una instancia de KNeighborsClassifier\n",
    "    # kneighbors nos devuelve los vecinos más cercanos de cada ejemplo en X y las distancias asociadas\n",
    "        # distancias y vecinos serán matrices de numEjemplos x k+1 elementos\n",
    "    distancias, vecinos = clasificador.kneighbors(X, n_neighbors=clasificador.n_neighbors + 1, return_distance=True)\n",
    "    # Realmente no estamos interesados en el propio vecino, sino en la clase a la que pertenece\n",
    "    # Transformamos los vecinos a una matriz con la clase de cada vecino\n",
    "    # Accedemos a las clases de los ejemplos de entrenamiento (atributo -y del clasificador knn) \n",
    "        # y cogemos los elementos en las posiciones de los vecinos calculados anteriormente\n",
    "    vecinosClase = clasificador._y[vecinos] # probar si funciona igual porque entiendo que si y es mucho más fácil (para train va mal)\n",
    "    \n",
    "    # Ahora queda decidir la clase de salida para cada uno de los ejemplos\n",
    "    # Debemos tener en cuenta: Si la distancia al primer vecino es 0, el vecino es el propio ejemplo y por tanto no lo usamos para decidir\n",
    "    #   1. Obtenemos una máscara con los ejemplos en los que ocurre esto\n",
    "    #   2. Sustituimos la clase del primer vecino por la del último (el k+1 que sino no se utiliza)\n",
    "    #   3. Obtenemos la moda (stats.mode) (el valor más repetido de clase) para cada fila (cogiendo los k primeros valores)\n",
    "    mascara = distancias[:,0] == 0\n",
    "    vecinosClase[mascara,0] = vecinosClase[mascara,-1]\n",
    "    prediction =  stats.mode(vecinosClase[:,:-1],axis=1)[0]\n",
    "\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \"\"\"\n",
    "    Esta función se encajar de ejecutar un método de selección de instancias y dar los resultados sobre train y test\n",
    "    con el clasificador introducido como parámetro\n",
    "    :param funcionMetodo: Función con el método de selección de instancias a ejecutar\n",
    "    :param clasificador: Instancia del clasificador a utilizar para obtener la precisión en train y test\n",
    "    :param train: Conjunto de datos de entrenamiento leído del formato keel con campos data y target\n",
    "    :param test: Conjunto de datos de test leído del formato keel con campos data y target\n",
    "    :return: tupla con la máscara de ejemplos seleccionados, la precisión en train, precisión en test y porcentaje de reducción obtenido\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ejecutaMetodoIS(funcionMetodo, clasificador, X_train, y_train, X_test, y_test, verbose=True):\n",
    "    # Obtenemos el nombre del método. Como es una función utilizamos su campo __name__\n",
    "    nombreMetodo = funcionMetodo.__name__\n",
    "    if verbose:\n",
    "        print (\"Ejecutando \" + nombreMetodo + \"...\")\n",
    "    # Ejecutamos el método de selección de instancias correspondiente con los ejemplos de entrenamiento y sus clases\n",
    "        # Utilizad todos los métodos con los parámetros por defecto y almacenad la máscara devuelta en una variable llamada S\n",
    "    S = funcionMetodo(X_train,y_train)\n",
    "    \n",
    "    # Entrenamos el clasificador correspondiente solo con los ejemplos seleccionados (aplicamos la máscara S)\n",
    "    clasificador.fit(X_train[S,:],y_train[S])\n",
    "\n",
    "#     # Obtenemos las salidas para train mediante leaveOneOut\n",
    "    predictionTrain = leaveOneOut(clasificador,X_train,y_train)\n",
    "\n",
    "#     # Obtenemos la precisión en train con las salidas obtenidas (tanto por uno)\n",
    "    accTrain = metrics.accuracy_score(predictionTrain,y_train)\n",
    "\n",
    "#     # Obtenemos las salidas para test \n",
    "#     # Obtenemos la precisión en test  (tanto por uno)\n",
    "    accTest = clasificador.score(X_test,y_test)\n",
    "\n",
    "    # Calculamos el porcentaje de reducción\n",
    "    reduction = 100 - S.sum() / float(S.size)*100\n",
    "\n",
    "    if verbose:\n",
    "        # print(\"Dataset \" + dataset)\n",
    "        print(\"Resultados \" + nombreMetodo + \" python\")\n",
    "        print(\"Precisión en train: {}\".format(accTrain))\n",
    "        print(\"Precisión en test: {}\".format(accTest))\n",
    "        print(\"Reducción \" + nombreMetodo + \": {} de {}\".format(S.sum(), S.size))\n",
    "        print(\"Reducción: %2.2f%%\" % reduction)\n",
    "        # En caso de ser un árbol, imprimimos el número de reglas obtenidas\n",
    "        if type(clasificador) == tree.DecisionTreeClassifier:\n",
    "            print(\"Número de reglas: {}\".format(clasificador.tree_.node_count))\n",
    "\n",
    "    # Mostramos los resultados obtenidos por el método gráficamente\n",
    "    # mostrar(clasificador, X_train, y_train, X_test, y_test,  nombreMetodo, X_train[S, :], y_train[S])\n",
    "\n",
    "    # Si es un árbol, devolvemos el número de reglas obtenidas\n",
    "    nReglas = -1\n",
    "    if type(clasificador) == tree.DecisionTreeClassifier:\n",
    "        nReglas = clasificador.tree_.node_count\n",
    "    return S, accTrain, accTest, reduction, nReglas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN(X, y, k=1):\n",
    "    \"\"\"\n",
    "    Algoritmo CNN para la selección de instancias. Se comienza con dos ejemplos aleatorios (uno de cada clase) y cada ejemplo\n",
    "    que se falla al ser clasificado por los ya seleccionados se añade a la selección (se para cuando ya no se añaden más ejemplos)\n",
    "    :param X: Matriz con los ejemplos de entrenamiento (se asume que los ejemplos están normalizados)\n",
    "    :param y: Vector con la salida de los ejemplos en X\n",
    "    :param k: Valor de k a utilizar en ENN\n",
    "    :return: Vector con la máscara de instancias seleccionadas \n",
    "            (La posición S[i]=True indica que la instancia i ha sido seleccionada y False lo contrario)\n",
    "    \"\"\"\n",
    "    # Como usamos aleatorios en RNN establecemos la semilla para que el test sea correcto y siempre obtengamos el mismo resultado\n",
    "    np.random.seed(12312)\n",
    "    # Creamos el clasificador knn con el valor de k dado\n",
    "    knn = neighbors.KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "    # S es una máscara de booleanos que indica si el ejemplo en la posición i está seleccionado (True) o no lo está (False)\n",
    "    S = np.zeros((X.shape[0]),dtype=bool)\n",
    "\n",
    "    # Inicialmente, seleccionamos aleatoriamente una instancia de cada clase\n",
    "    # Anotamos el número de clases\n",
    "    nClases = np.unique(y)\n",
    "\n",
    "    # Para cada clase, buscamos los índices de los ejemplos de dicha clase y seleccionamos uno de ellos aleatoriamente\n",
    "    # Dicho ejemplo coge el valor True en S\n",
    "    for c in nClases:\n",
    "        indicesClase = np.where(y == c)[0]  # np.where devuelve una tupla, nos interesa la primera parte que contiene los índices de las posiciones que no son 0 o False\n",
    "        # Elegid una instancia aleatoriamente de las de la clase: utilizad randint de Numpy para ello\n",
    "        instanciaAleatoria = indicesClase[np.random.randint(0,indicesClase.size)]\n",
    "        # Modificad la máscara S de acuerdo a la instancia seleccionada\n",
    "        S[instanciaAleatoria] = True\n",
    "\n",
    "    # Solo evaluamos los ejemplos que no están en S (los que están se aciertan por definición al considerlos\n",
    "    # como vecinos de sí mismos). Estos ejemplos son los únicos que podemos añadir a S\n",
    "    notS = S == False\n",
    "\n",
    "    # \"Entrenamos\" knn con los ejemplos seleccionados\n",
    "    knn.fit(X[S,:],y[S])\n",
    "    \n",
    "    # Inicializamos el número de fallados para entrar en el bucle. El algoritmo termina cuando no se fallan ejemplos\n",
    "    fallados = -1\n",
    "    while fallados != 0:\n",
    "        # Ponemos el contador de fallados a 0 y comprobamos todos los ejemplos no seleccionados\n",
    "        fallados = 0\n",
    "        # Obtenemos los índices de los ejemplos no seleccionados: utilizad np.where como se ha hecho anteriormente\n",
    "        indices = np.where(notS)[0]\n",
    "\n",
    "        # Para cada ejemplo no seleccionado (y en orden aleatorio) comprobamos si dicho ejemplo se falla         \n",
    "        # con las instancias en S actualmente. Si se falla, el ejemplo se añade a S, se reentrena KNN y se suma uno a fallados\n",
    "        for i in np.random.permutation(indices):\n",
    "            if y[i] != knn.predict(X[i, :].reshape(1, -1)):\n",
    "                S[i] = True\n",
    "                knn = knn.fit(X[S, :], y[S])\n",
    "                fallados += 1\n",
    "\n",
    "        # Recalculamos los ejemplos a estudiar en la próxima iteración, aquellos no seleccionados\n",
    "        notS = np.logical_not(S)\n",
    "        print(\"CNN, fin de iteración, fallados: {}, ejemplos en S: {}\".format(fallados, np.sum(S)))\n",
    "\n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNN(X, y, k=1):\n",
    "    \"\"\"\n",
    "    Algoritmo RNN para la selección de instancias. Se parte de la selección obtenida con CNN y se eliminan aquellas instancias\n",
    "    que no provoquen que se falle ninguna instancia no seleccionada (las seleccionadas se aciertan por definición al estar en el subconjunto)\n",
    "    :param X: Matriz con los ejemplos de entrenamiento (se asume que los ejemplos están normalizados)\n",
    "    :param y: Vector con la salida de los ejemplos en X\n",
    "    :param k: Valor de k a utilizar en ENN\n",
    "    :return: Vector con la máscara de instancias seleccionadas \n",
    "            (La posición S[i]=True indica que la instancia i ha sido seleccionada y False lo contrario)\n",
    "    \"\"\"\n",
    "    # Como usamos aleatorios en RNN establecemos la semilla para que el test sea correcto y siempre obtengamos el mismo resultado\n",
    "    np.random.seed(12312)\n",
    "    # Creamos el clasificador knn con el valor de k dado\n",
    "    knn = neighbors.KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "    # En RNN partimos de la selección realizada por CNN y eliminamos ejemplos de la misma\n",
    "    # S es una máscara de booleanos que indica si el ejemplo en la posición i está seleccionado (True) o no lo está (False)\n",
    "    S = CNN(X,y,k)\n",
    "\n",
    "    # Entrenamos KNN con el conjunto de instancias seleccionadas por CNN\n",
    "    knn.fit(X[S,:],y[S])\n",
    "\n",
    "    # Obtenemos la máscara de instancias no seleccionadas\n",
    "    # No podemos fallar ninguna de estas si queremos eliminar una instancia de S\n",
    "    notS = S == False\n",
    "\n",
    "    # Recorremos las instancias seleccionadas para ver si podemos eliminarlas o no\n",
    "    # Obtenemos para ello los índices de las instancias: utilizad np.where\n",
    "    indices = np.where(S)[0]\n",
    "\n",
    "    # y las recorremos aleatoriamente:\n",
    "    for i in np.random.permutation(indices):\n",
    "        # Asumimos que podemos eliminar la instancia y la \"eliminamos\" temporalmente: intercambio de valores en las máscaras S y Snot\n",
    "        S[i],notS[i] = notS[i],S[i]\n",
    "\n",
    "        # Entrenamos knn una vez eliminada la instancia\n",
    "        knn.fit(X[S,:],y[S])\n",
    "\n",
    "        # Obtenemos las salidas para los ejemplos que no están seleccionados\n",
    "        salidas = knn.predict(X[notS,:])\n",
    "\n",
    "        # Si todos los ejemplos no seleccionados son acertados (no se falla ninguno) mantenemos la eliminación (no hacemos nada)\n",
    "            # En otro caso, si fallamos alguna instancia, debemos restablecer la instancia eliminada: deshacer el intercambio en las máscaras\n",
    "        if np.sum(y[notS] != salidas) != 0:\n",
    "            S[i], notS[i] = notS[i], S[i]\n",
    "\n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcularMediaDesviacion(datos):\n",
    "    media = datos.mean(axis=0)\n",
    "    desviacion = datos.std(axis=0)\n",
    "    return media,desviacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deteccionOutliers(datos,media,desviacion,k=2):\n",
    "    variablesOutliers = (datos < (media - k*desviacion)) | (datos > (media + k*desviacion))\n",
    "    mascaraOutliers = variablesOutliers.sum(axis=1,dtype=bool)\n",
    "    indicesOutliers = np.array(range(len(datos)))[mascaraOutliers]\n",
    "    return indicesOutliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "existe 5715 filas de Outliers.\n"
    }
   ],
   "source": [
    "index_col_num = np.ones(len(datos_ok.columns))\n",
    "\n",
    "for i,val in enumerate(datos_ok.columns):\n",
    "\n",
    "    if val in categorico:\n",
    "        index_col_num[i] = 0\n",
    "\n",
    "## no cogemos la ultima variable porque es la clase\n",
    "index_col_num = index_col_num[:-1].astype('bool')\n",
    "\n",
    "media,desviacion = calcularMediaDesviacion(X.T[index_col_num].T)\n",
    "\n",
    "indicesOutliers = deteccionOutliers(X.T[index_col_num].T,media,desviacion)\n",
    "print('existe',len(indicesOutliers), 'filas de Outliers.')\n",
    "\n",
    "XsinOut = np.delete(X, indicesOutliers, axis=0)\n",
    "YsinOut = np.delete(y, indicesOutliers, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(XsinOut, YsinOut, train_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Ejecutando RNN...\nCNN, fin de iteración, fallados: 1108, ejemplos en S: 1110\nCNN, fin de iteración, fallados: 312, ejemplos en S: 1422\nCNN, fin de iteración, fallados: 28, ejemplos en S: 1450\nCNN, fin de iteración, fallados: 1, ejemplos en S: 1451\nCNN, fin de iteración, fallados: 0, ejemplos en S: 1451\nResultados RNN python\nPrecisión en train: 0.8415584415584415\nPrecisión en test: 0.8490661282180717\nReducción RNN: 1210 de 4620\nReducción: 73.81%\nWall time: 4min 2s\n"
    }
   ],
   "source": [
    "%%time\n",
    "knn = neighbors.KNeighborsClassifier()\n",
    "_, accTrain, accTest, reduction, _ = ejecutaMetodoIS(RNN, knn, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}